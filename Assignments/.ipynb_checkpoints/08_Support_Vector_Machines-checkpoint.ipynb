{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Support Vector Machines</h1></center>\n",
    "\n",
    "In this notebook, we'll cover one of the major algorithms used in Supervised Learning--**_Support Vector Machines_** (or _SVMs_ for short!). We'll start by playing around with a visual implementation to gain an intuition for how SVMs work, and then we'll grab an SVM implementation from `sklearn` and use to it make some classifcations on a real world data set.  \n",
    "\n",
    "<center><h3>How Support Vector Machines Work</h3></center>\n",
    "\n",
    "at first glance, SVMs are similar to other supervised learning algorithms such as Logistic Regression, because the algorithm find the optimal line for a decision boundary.  However, unlike Logistic Regression, SVMs don't just find a line for the decision boundary--they try to maximize the margin between the two sides. \n",
    "\n",
    "<center><img src='img/svm_boundary.png' height=40% width=40%></center>\n",
    "\n",
    "The points that touch the sides of the margin are called **_support vectors_**.  By maximizing the margin by finding support vectors, this has the effect of \"balancing\" the the decision boundary so that it evenly splits the area between the two classes.  This is not always the case with Logistic Regression--see the image below for a visual example.  \n",
    "\n",
    "<center><img src=\"img/svm_vs_lr.png\"></center>\n",
    "\n",
    "Notice that on the image on the right, the line is a bit skewed through the datapoints.  This is a problem that can occur with Logistic Regression, since it's job is to fit a line that linearly separates the two classes. The line in the image on the right _technically_ accomplishes this task, but we can see by looking at the decision boundary that this is not optimal. Contrast this with the decision boundary on the left, which splits the area between the two classes perfectly.  \n",
    "\n",
    "<center><h3>Linear Separability and Kernel Methods</h3></center>\n",
    "\n",
    "SVMs are not perfect, however--they only work when the data is **_linearly separable_**--that is, the decision boundary is linear, and can be drawn as a straight line.  Take a look at the picture below, and consider where you would draw the ideal decision boundary to split the two--remember, it has to be a straight line!\n",
    "\n",
    "<center><img src='img/before_kernel.png' height=50% width=50%></center>\n",
    "\n",
    "The data is non linearly separable, so we can't draw a decision boundary--or can we?  This is where the cool part of SVMs comes in--what if we mapped the data to a **_higher-dimension space_**--maybe we could draw a decision boundary there?\n",
    "\n",
    "<center><img src='img/after_kernel.png'></center>\n",
    "\n",
    "Ah, there it is! In this higher dimensional space, we can see an easy place to draw a linear decision boundary.  It's important to note that in 2 dimensions, our decision boundary looks like a straight line--but for this data, in its current form, our decision boundary will need to look like a piece of paper (with no thickness). This is because our decision boundary will always have one less dimension than the data we are trying to find a decision boundary for.  If our data has 4 dimensions (which we can't visualize), then our decision boundary would be a **_hyperplane_** that would look like a rectangle.  We can generalize this rule to say that for any dataset with \\[n\\] dimensions, our decision boundary will have \\[n - 1\\] dimensions. \n",
    "\n",
    "The process of mapping data to a higher-dimensional space is called the **_Kernel Method_**.  There are several different kernels that are typically used, but the most common ones you'll typically need to know are the **_Polynomial Kernel_** and the **_Radial Basis Function (RBF)_**--these are complicated data transformations that any ML library worth its salt can handle for you. You don't need to know the math behind them, but you should definitely be aware that they exist, and that they are tools in your ML toolbox for SVMs!\n",
    "\n",
    "<center>The Final Step</center>\n",
    "\n",
    "Let's review what we've done so far:\n",
    "\n",
    "1.  Determined that the data is not linearly separable in its current form.\n",
    "2.  Mapped the data to a higher dimensional space using a kernel method.\n",
    "3.  Found a linear decision boundary in the higher dimensional space. \n",
    "\n",
    "Now what?\n",
    "\n",
    "Now that we've identified support vectors that allow us to linearly separate the data in a higher dimensional space, all that we need to do is to bring the data (and the decision boundary) back to our original, lower-dimensional space.  If we visualize the decision boundary for our data in the lower-dimensional space, it will appear as a circle:\n",
    "\n",
    "<center><img src='img/kernel_with_boundary.png'></center>\n",
    "\n",
    "It's important to understand that although our decision boundary isn't linear in this lower-dimensional space, that's okay--we found a linear decision boundary in a higher-dimensional space and made our classifications, so we didn't actually break the rules of Support Vector Machines.  \n",
    "\n",
    "<center><h3>Playing Around with SVMs</h3></center>\n",
    "\n",
    "To make learning how SVMs work a bit easier, the `sklearn` community has built an awesome interactive visualization that lets users plot points and fit an SVM for binary classification. We **_highly recommend_** running this python script and getting a feel for how SVMs work--plot different data points and see how the decision boundary changes, try different kernel methods, visualize the decision surface of the SVM, etc.  You'll find all of these activities very useful, and very interesting.  \n",
    "\n",
    "Check out [this link](http://scikit-learn.org/stable/auto_examples/applications/svm_gui.html#sphx-glr-auto-examples-applications-svm-gui-py) to see the page on sklearn.org that gives an example of how everything works. **_To download the file, download and run the python script linked at the bottom of the page (use the script version, not the jupyter notebook!)_**\n",
    "\n",
    "\n",
    "<center><h2>Challenge: Classifications with SVMs</h2></center>\n",
    "\n",
    "For the remainder of this notebook, you'll use everything you've learned in DS2 to use a Support Vector Classifier on the [Wisconsin Breast Cancer Dataset](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29).  Note that you **_do not need to download the dataset_**, as it comes preloaded as a sample in sklearn.  To get the data, just use the `load_breast_cancer()` method found within `sklearn.datasets`.\n",
    "\n",
    "**_Challenge_**:\n",
    "\n",
    "1.  Import and explore the dataset.  Recall the `load_breast_cancer()` method will return an object that contains the data in `.data`, the labels in `.target`, and the column names in `.feature_names` attributes.  \n",
    "2.  Build a **_Correlation Heatmap_** using **_Seaborn_** to check for each feature's correlation with the labels. \n",
    "3.  Build a second **_Correlation Heatmap_** using **_Seaborn_** to check for **_mutlicollinearity_** between features.  \n",
    "4.  Scale and transform the data using a `StandardScaler()` object and any appropriate methods it contains.\n",
    "5.  Split the newly scaled data into training and testing sets using `train_test_split()`.\n",
    "6.  Create an `SVC()` object, which can be found in `sklearn.svm`\n",
    "7.  Fit the model to the scaled data. \n",
    "8.  Use your validation data to check the accuracy metrics for your model.  \n",
    "\n",
    "\n",
    "**_Stretch Challenge_**: \n",
    "\n",
    "1. Try different parameters such as different kernels to see how it affects the overall performance of the model.  For a full list of the tunable parameters you can use with an SVC, see [the documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) on sklearn.org. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Fixing Up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "# a look at the properties of the dataset\n",
    "print(breast_cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# the 'DESCR' will give us a description\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's: 357\n",
      "Number of 0's: 212\n"
     ]
    }
   ],
   "source": [
    "# How do we know which class is represented by 0? By 1?\n",
    "# I check by looking at the number of 0's and 1's, and cross-comparing with the amounts given for the classes in \n",
    "# the dataset description.\n",
    "\n",
    "print(f\"Number of 1's: {len([value for value in breast_cancer.target if value == 1])}\")  # this is same as Benign\n",
    "print(f\"Number of 0's: {len([value for value in breast_cancer.target if value == 0])}\")  # this is same as Malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    }
   ],
   "source": [
    "# quick look at the data values\n",
    "print(breast_cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of the dataset\n",
    "print(breast_cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a DataFrame object\n",
    "import pandas as pd\n",
    "\n",
    "cancer = pd.DataFrame(breast_cancer.data)\n",
    "cancer.columns = breast_cancer.feature_names\n",
    "target_var = 'Is_Benign'  # 1 means True (or positive), and 0 is malignancy\n",
    "cancer[target_var] = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Is_Benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Is_Benign  \n",
       "0          0.4601                  0.11890          0  \n",
       "1          0.2750                  0.08902          0  \n",
       "2          0.3613                  0.08758          0  \n",
       "3          0.6638                  0.17300          0  \n",
       "4          0.2364                  0.07678          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What percentage of tumors were classified as benign in this study? As malignant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Tumors as Benign: 62.7417%\n",
      "Percentage of Tumors as Malignant: 37.2583%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "We know from the description of the dataset above that in this study,\n",
    "that out of 569 total samples,\n",
    "there were 212 classifications made for malignant, and\n",
    "357 classifications made for benign tumors.\n",
    "'''\n",
    "per_mal = round(212/len(cancer) * 100, 4)\n",
    "per_ben = round(357/len(cancer) * 100, 4)\n",
    "print(f'Percentage of Tumors as Benign: {per_ben}%')\n",
    "print(f'Percentage of Tumors as Malignant: {per_mal}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualized Using a Pie Chart\n",
    "\n",
    "labels = ['Benign', 'Malignant']\n",
    "population_sizes = [357, 212]\n",
    "explode = (0.0, 0.1)  # only explode the malignant class\n",
    "\n",
    "plt.pie(population_sizes, explode=explode, labels=labels, autopct='%1.1f%%',)\n",
    "plt.title('Percentages of Benign and Malignant Tumors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting! \n",
    "So it looks as if roughly 2/3 of the data samples in this study came from benign breast cancer tumors. This may be relevant to us later - while still a minority in the dataset population, the rate of malignant tumors in this study is much greater than the incidence rate for breast cancer in 1995, for the total U.S. population.\n",
    "\n",
    "### Breast Cancer in 1995:\n",
    "Unfortunately it's difficult to compare how breast cancer has changed over time, at least if you go before the 21st century. According to a [paper published in \"A Cancer Journal for Physicians\"](https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/canjclin.45.1.8), in 1995 there was \"no nationwide cancer registry\"\n",
    "like today - therefore we have no exact\n",
    "number for the new cases of cancer are diagnosed in the United States in that year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaying Distribution of Both Classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area of the Tumor\n",
    "It seems obvious that one of the features of this dataset, the area of the tumor, will be represented higher in the population of malignant tumors than in that of the benign tumor population.\n",
    "\n",
    "Is this true? Time to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_mean_(df, feature, population_class=None):\n",
    "    '''Calculates the average value for a feature, amongst one of the two classes.'''\n",
    "    if population_class is not None:\n",
    "        # calculate the mean for one of the attributes, for only malignant samples or only benign\n",
    "        pop_subset = df[df['Is_Benign'] == population_class]\n",
    "    else:\n",
    "        # calculate the mean for one of the attributes, the whole population\n",
    "        pop_subset = df\n",
    "    avg = round(pop_subset[feature].mean(), 4)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean area amongst the samples classified as malignant is: 978.3764 square cm.\n"
     ]
    }
   ],
   "source": [
    "mal_area_mean = get_feature_mean_(cancer, 'mean area', 0)\n",
    "print(f'The mean area amongst the samples classified as malignant is: {mal_area_mean} square cm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean area amongst the samples classified as benign is: 462.7902 square cm.\n"
     ]
    }
   ],
   "source": [
    "ben_area_mean = get_feature_mean_(cancer, 'mean area', 1)\n",
    "print(f'The mean area amongst the samples classified as benign is: {ben_area_mean} square cm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
