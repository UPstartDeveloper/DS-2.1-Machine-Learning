{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def covariance(ls_x, ls_y):\n",
    "    summation = 0\n",
    "    for i in range(len(ls_x)):\n",
    "        x_factor = (ls_x[i] - np.mean(ls_x))\n",
    "\n",
    "        y_factor = (ls_y[i] - np.mean(ls_y))\n",
    "        \n",
    "        summation += x_factor * y_factor\n",
    "    \n",
    "    return (1/len(ls_x) - 1) * summation \n",
    "\n",
    "covariance(np.array(range(4)), np.array([1, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 23]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication in numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 0], [1, 5]])\n",
    "v = np.array([3, 4])\n",
    "\n",
    "print(np.dot(A, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(v, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_value, eig_vector = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 2.]\n",
      "\n",
      "[[ 0.          0.9486833 ]\n",
      " [ 1.         -0.31622777]]\n"
     ]
    }
   ],
   "source": [
    "print(eig_value)  # this tells us that 5 is the eigen value for first column of A, and 2 is same for second column\n",
    "print('')\n",
    "print(eig_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "# Verify Av = av\n",
    "\n",
    "print(A * np.array([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 5.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_value[0]*eig_vector[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8973666 , -0.63245553])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, eig_vector[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8973666 , -0.63245553])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# multiply the other eigen-value of A with its associated eigen-vector\n",
    "eig_value[1]*eig_vector[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('Datasets/pca_uk.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>England</th>\n",
       "      <th>N Ireland</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>Wales</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375</td>\n",
       "      <td>135</td>\n",
       "      <td>458</td>\n",
       "      <td>475</td>\n",
       "      <td>Alcoholic drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>73</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>267</td>\n",
       "      <td>242</td>\n",
       "      <td>227</td>\n",
       "      <td>Carcase meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1472</td>\n",
       "      <td>1494</td>\n",
       "      <td>1462</td>\n",
       "      <td>1582</td>\n",
       "      <td>Cereals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>Confectionery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>235</td>\n",
       "      <td>Fats and oils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>93</td>\n",
       "      <td>122</td>\n",
       "      <td>160</td>\n",
       "      <td>Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1102</td>\n",
       "      <td>674</td>\n",
       "      <td>957</td>\n",
       "      <td>1137</td>\n",
       "      <td>Fresh fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>720</td>\n",
       "      <td>1033</td>\n",
       "      <td>566</td>\n",
       "      <td>874</td>\n",
       "      <td>Fresh potatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253</td>\n",
       "      <td>143</td>\n",
       "      <td>171</td>\n",
       "      <td>265</td>\n",
       "      <td>Fresh Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>685</td>\n",
       "      <td>586</td>\n",
       "      <td>750</td>\n",
       "      <td>803</td>\n",
       "      <td>Other meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>488</td>\n",
       "      <td>355</td>\n",
       "      <td>418</td>\n",
       "      <td>570</td>\n",
       "      <td>Other Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>198</td>\n",
       "      <td>187</td>\n",
       "      <td>220</td>\n",
       "      <td>203</td>\n",
       "      <td>Processed potatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>334</td>\n",
       "      <td>337</td>\n",
       "      <td>365</td>\n",
       "      <td>Processed Veg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1374</td>\n",
       "      <td>1506</td>\n",
       "      <td>1572</td>\n",
       "      <td>1256</td>\n",
       "      <td>Soft drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156</td>\n",
       "      <td>139</td>\n",
       "      <td>147</td>\n",
       "      <td>175</td>\n",
       "      <td>Sugars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    England  N Ireland  Scotland  Wales            Features\n",
       "0       375        135       458    475    Alcoholic drinks\n",
       "1        57         47        53     73           Beverages\n",
       "2       245        267       242    227        Carcase meat\n",
       "3      1472       1494      1462   1582             Cereals\n",
       "4       105         66       103    103              Cheese\n",
       "5        54         41        62     64       Confectionery\n",
       "6       193        209       184    235       Fats and oils\n",
       "7       147         93       122    160                Fish\n",
       "8      1102        674       957   1137         Fresh fruit\n",
       "9       720       1033       566    874      Fresh potatoes\n",
       "10      253        143       171    265           Fresh Veg\n",
       "11      685        586       750    803          Other meat\n",
       "12      488        355       418    570           Other Veg\n",
       "13      198        187       220    203  Processed potatoes\n",
       "14      360        334       337    365       Processed Veg\n",
       "15     1374       1506      1572   1256         Soft drinks\n",
       "16      156        139       147    175              Sugars"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 375   57  245 1472  105   54  193  147 1102  720  253  685  488  198\n",
      "   360 1374  156]\n",
      " [ 135   47  267 1494   66   41  209   93  674 1033  143  586  355  187\n",
      "   334 1506  139]\n",
      " [ 458   53  242 1462  103   62  184  122  957  566  171  750  418  220\n",
      "   337 1572  147]\n",
      " [ 475   73  227 1582  103   64  235  160 1137  874  265  803  570  203\n",
      "   365 1256  175]]\n",
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# build a matrix of the feature values, not including the text labels\n",
    "X = np.array([df[i].values for i in df.columns if i != 'Features'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "# calculate the PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Find the principle components of 17 features\n",
    "X_r = pca.fit_transform(X)  # data in reduced dimensionality format\n",
    "# X_r = pca.fit_transform(X.T) # using x in transposed form, so it comes out in columns (among other things)\n",
    "\n",
    "print(X_r)  # unfortunately, there are no names to be specified for these values\n",
    "# but the rows do show the 2 value feature for each our four original classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Lets visualize the principle components - differentiation!!! (but not knowing the name of dimensions)\n",
    "\n",
    "for feature, (plot_x,plot_y) in enumerate(zip(X_r[:, 0], X_r[:, 1])):\n",
    "    plt.scatter(plot_x, plot_y)\n",
    "    plt.text(plot_x+0.3, plot_y+0.3, df.columns[:-1][feature])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-144.99315218   -2.53299944]\n",
      " [ 477.39163882  -58.90186182]\n",
      " [ -91.869339    286.08178613]\n",
      " [-240.52914764 -224.64692488]]\n",
      "[105073.34576714  45261.62487597]\n",
      "[0.67444346 0.29052475]\n",
      "[0.67444346 0.96496821]\n"
     ]
    }
   ],
   "source": [
    "# How much info is preserved by PCA?\n",
    "\n",
    "# PCA computation by sklearn\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "print(X_r)\n",
    "print(pca.explained_variance_) # super useful method!\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())  # over 95% info preserved~ this tells us we have the right number of PC's!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of PCA Component:\n",
      "(0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# calcualtion the correlation between PC1 other PC\n",
    "import scipy\n",
    "print('Correlation of PCA Component:')\n",
    "print(scipy.stats.pearsonr(X_r[:, 0], X_r[:, 1]))  # remember, we WANTED to remove the correlation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def reverse_without_numpy(ls):\n",
    "    new = n\n",
    "'''\n",
    "\n",
    "def reverse_list(ls):\n",
    "    return ls[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_list([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own function to obtain principal components\n",
    "X = np.array([[1, 1, 1], [1, 2, 1], [1, 3, 2], [1, 4, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_matrix(X):\n",
    "    return np.array([X[:, col_num] - np.mean(X[:, col_num]) for col_num in range(X.shape[1])]).T\n",
    "\n",
    "def pca(X, n_components=2):\n",
    "    centered = center_matrix(X)\n",
    "    eig_val, eig_vec = np.linalg.eig(np.cov(centered))\n",
    "    sorted_vals = np.argsort(eig_val)[-n_components:][::-1]\n",
    "    print(sorted_vals)\n",
    "    print(\"eig vec\", eig_vec[:, sorted_vals])\n",
    "    print(\"centered\", centered)\n",
    "    return np.dot(eig_vec[:, sorted_vals].T, centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "eig vec [[-0.63281645  0.59122191]\n",
      " [-0.27179185 -0.71376644]\n",
      " [ 0.21093882 -0.19707397]\n",
      " [ 0.69366948  0.3196185 ]]\n",
      "centered [[ 0.   -1.5  -0.75]\n",
      " [ 0.   -0.5  -0.75]\n",
      " [ 0.    0.5   0.25]\n",
      " [ 0.    1.5   1.25]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.23109423,  1.59827778],\n",
       "       [ 0.        , -0.14905888,  0.44216303]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(X, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.65392786 -0.2775295 ]\n",
      " [-0.84584087  0.31153366]\n",
      " [ 0.55130929  0.09250983]\n",
      " [ 1.94845944 -0.126514  ]]\n",
      "[2.5171201  0.06621324]\n",
      "[0.97436907 0.02563093]\n",
      "[0.97436907 1.        ]\n",
      "Correlation of PCA Component:\n",
      "(3.885780586188048e-16, 0.9999999999999996)\n",
      "[[0.         0.         0.        ]\n",
      " [0.         1.66666667 1.16666667]\n",
      " [0.         1.16666667 0.91666667]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.65392786,  0.2775295 ],\n",
       "       [-0.84584087, -0.31153366],\n",
       "       [ 0.55130929, -0.09250983],\n",
       "       [ 1.94845944,  0.126514  ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "\n",
    "# PCA computation by sklearn\n",
    "\n",
    "X = np.array([[1, 1, 1], [1, 2, 1], [1, 3, 2], [1, 4, 3]])\n",
    "# print(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit_transform(X)\n",
    "print(X_r)\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "print('Correlation of PCA Component:')\n",
    "print(scipy.stats.pearsonr(X_r[:, 0], X_r[:, 1]))\n",
    "\n",
    "\n",
    "# Our own function to compare \n",
    "def PCA_calculation(data, n_comp=2):\n",
    "    M = np.mean(data, axis=0)\n",
    "    # center columns by subtracting column means\n",
    "    C =  M - data\n",
    "    # calculate covariance matrix of centered matrix\n",
    "    V = np.cov(C.T)\n",
    "    print(V)\n",
    "    # eigen decomposition of covariance matrix\n",
    "    eig_value, eig_vector = np.linalg.eig(V)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = np.argsort(eig_value)[::-1] \n",
    "    idx_n_comp = idx[:n_comp]\n",
    "    # eigenvectors according to top n_comp largest\n",
    "    eig_vector = eig_vector[:, idx_n_comp]\n",
    "    P = np.dot(C, eig_vector)\n",
    "    return P\n",
    "\n",
    "\n",
    "PCA_calculation(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Apply Principle to Boston housing features and then train the linear regression model\n",
    "Basically, we remove correlation among features with PCA\n",
    "\n",
    "We do not need to do feature data scaling (normalization) when we do PCA for features, because\n",
    "\n",
    "Report the R-squared and MSE for a system with PCA+Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlation among features in Boaton data - scaling not required\n",
    "# report the information preserves\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting training data\n",
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "target_var = 'MEDV'\n",
    "df[target_var] = boston.target\n",
    "X = df[boston.feature_names]\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into scaled training and test data\n",
    "\n",
    "def scale_data(data, scaler, target_var):\n",
    "    \"\"\"Scales the specified features of the dataset, using the scaler. \n",
    "       Returns DataFrame and data needed to make linear regression model.\n",
    "    \"\"\"\n",
    "    # make a DataFrame from the data\n",
    "    df = pd.DataFrame(data.data)\n",
    "    df.columns = data.feature_names\n",
    "    df[target_var] = data.target\n",
    "    # split the data\n",
    "    X = df[data.feature_names]\n",
    "    y = data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    # scale the training and testing data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return df, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# import from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# instantiate the scaler object\n",
    "standard_scaler = StandardScaler()\n",
    "# make the DataFrame, with scaled training and testing data\n",
    "standard_df, X_train_scaled, X_test_scaled, y_train, y_test = scale_data(boston, standard_scaler, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.25982453 -1.09602895 -1.58686145 ...  0.04533298 -0.77202009\n",
      "  -0.71635666]\n",
      " [-1.87734414 -1.09685975 -0.98053554 ... -0.04967336 -0.06064333\n",
      "  -0.39181321]\n",
      " [-2.51208752  1.4533637   1.775388   ...  0.36686172 -0.54924378\n",
      "   0.49870808]\n",
      " ...\n",
      " [ 0.03814707  0.74414144 -0.48979114 ... -0.12583215  0.23420077\n",
      "  -0.32417165]\n",
      " [-0.94925813  0.35576387 -1.41581584 ...  0.73867413 -0.67405691\n",
      "  -0.46130744]\n",
      " [-0.38481242  1.00499051 -1.10244654 ...  0.53857373  0.07246543\n",
      "  -0.98882986]]\n",
      "But is this the right amount of principle components?\n",
      "[6.10157016 1.41936305 1.27643939 0.92442932 0.8158221  0.68438946\n",
      " 0.54593187 0.38234911 0.28165905]\n",
      "[0.46811316 0.10889369 0.09792857 0.07092232 0.06258996 0.05250644\n",
      " 0.04188396 0.02933387 0.02160891]\n",
      "[0.46811316 0.57700685 0.67493543 0.74585775 0.80844771 0.86095415\n",
      " 0.9028381  0.93217197 0.95378089]\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA on X_train\n",
    "pca = PCA(n_components=9)\n",
    "X_train_reduced = pca.fit_transform( X_train_scaled)\n",
    "\n",
    "print(X_train_reduced)\n",
    "\n",
    "# Obtain required number of principal components\n",
    "print('But is this the right amount of principle components?')\n",
    "print(pca.explained_variance_) # super useful method!\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data normalization on X_train_reduced\n",
    "X_train_reduced_scaled = pca.fit_transform(X_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Time: 0.0006120204925537109 miliseconds\n",
      "\n",
      "Y-intercept of Regression Line: 22.608707124010557 \n",
      "\n",
      "Weight values of Regression Line: \n",
      "[-2.44698073  2.14477667  3.62563979 -0.28010938 -1.96868334 -0.20433543\n",
      " -0.32141186  0.96300333  0.1708308 ]\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "\n",
    "def time_fitting(fitter):\n",
    "    '''Record and display the time taken to train the model.'''\n",
    "    start = time.time()\n",
    "    fitter()\n",
    "    end = time.time()\n",
    "    print(f'Fitting Time: {end-start} miliseconds')\n",
    "\n",
    "def make_trained_model(X_train, y_train):\n",
    "    \"\"\"Return a Linear Regression model fitted to the training data. \n",
    "       Prints intercept and coefficients.\n",
    "       \n",
    "       Parameters:\n",
    "       X_train(list): training data for features of dataset\n",
    "       y_train(list): training data for target value\n",
    "\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    # fit the model and time it\n",
    "    time_fitting(lambda: model.fit(X_train, y_train))\n",
    "    print()\n",
    "    # print intercept and coefficients\n",
    "    print(f'Y-intercept of Regression Line: {model.intercept_} \\n')\n",
    "    print(f'Weight values of Regression Line: \\n{model.coef_}')\n",
    "    return model\n",
    "\n",
    "model = make_trained_model(X_train_reduced_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (127,13) (9,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-0b95fb48e1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/dev/courses/DS/DS-2.1-Machine-Learning/env/lib/python3.7/site-packages/sklearn/decomposition/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (127,13) (9,) "
     ]
    }
   ],
   "source": [
    "\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
