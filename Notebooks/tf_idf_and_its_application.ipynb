{
 "cells": [
  {
   "cell_type": "markdown",

=======
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- How we can exctract keywords from corpus (collections of texts) using TF-IDF\n",
    "\n",
    "- Explain what is TF-IDF\n",
    "\n",
    "- Applications of keywords exctraction algorithm and Word2Vec"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## Review: What are the pre-processings to apply a machine learning algorithm on text data?\n",
    "\n",
    "1. The text must be parsed to words, called tokenization\n",
    "\n",
    "2. Then the words need to be encoded as integers or floating point values\n",
    "\n",
    "3. scikit-learn library offers easy-to-use tools to perform both tokenization and feature extraction of text data"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## What is TF-IDF Vectorizer?\n",
    "\n",
    "- Word counts are a good starting point, but are very basic\n",
    "\n",
    "An alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF. \n",
    "\n",
    "**Term Frequency**: This summarizes how often a given word appears within a document\n",
    "\n",
    "**Inverse Document Frequency**: This downscales words that appear a lot across documents"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## Intuitive idea behind TF-IDF:\n",
    "    \n",
    "- If a word appears frequently in a document, it's important. Give the word a high score\n",
    "\n",
    "- But if a word appears in many documents, it's not a unique identifier. Give the word a low score\n",
    "\n",
    "<img src=\"Images/tfidf_slide.png\" width=\"700\" height=\"700\">"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## Activity: Obtain the keywords from TF-IDF\n",
    "\n",
    "1- First obtain the TF-IDF matrix for given corpus\n",
    "\n",
    "2- Do column-wise addition\n",
    "\n",
    "3- Sort the score from highest to lowest\n",
    "\n",
    "4- Return the associated words based on step 3"

   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.78528828 0.         0.6191303  0.        ]\n",
      " [0.70710678 0.         0.         0.         0.70710678]\n",
      " [0.53256952 0.         0.         0.65782931 0.53256952]\n",
      " [0.36626037 0.         0.57381765 0.         0.73252075]]\n",
      "[('bright', 1.605936677684143), ('bule', 0.7852882757103967), ('shining', 0.5738176501168697), ('sky', 1.27695960978985)]\n"
     ]
    }
   ],
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def keyword_sklearn(docs, k):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "    print(tfidf_matrix.toarray())\n",
    "    print(vectorizer.get_feature_names())\n",
    "    tfidf_scores = np.sum(tfidf_matrix, axis=0)\n",
    "    tfidf_scores = np.ravel(tfidf_scores)\n",
    "    return sorted(dict(zip(vectorizer.get_feature_names(), tfidf_scores)).items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "documnets = ['The sky is bule', 'The sun is bright', 'The sun in the sky is bright', 'we can see the shining sun, the bright sun']\n",
    "\n",

    "print(keyword_sklearn(documnets, 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.         0.78528828 0.         0.6191303  0.        ]\n",
      " [0.70710678 0.         0.         0.         0.70710678]\n",
      " [0.53256952 0.         0.         0.65782931 0.53256952]\n",
      " [0.36626037 0.         0.57381765 0.         0.73252075]]\n",
      "['bright', 'bule', 'shining', 'sky', 'sun']\n",
      "[('sun', 1.9721970507561841), ('bright', 1.605936677684143), ('sky', 1.27695960978985)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
    "# print(keyword_sklearn(documnets, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "docs = ['The sky is bule', 'The sun is bright', 'The sun in the sky is bright', 'we can see the shining sun, the bright sun']\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "mat = vectorizer.fit_transform(docs)\n",
    "matrix = mat.toarray()\n",
    "print(matrix)\n",
    "# print(vectorizer.get_feature_names())  # which types of words do we have, after dropping stop words\n",
    "\n",
    "\n",
    "'''# column wise addition\n",
    "scores1 = sum(matrix[:, 0])\n",
    "print(scores1)\n",
    "scores2 = sum(matrix[:, 1])\n",
    "print(scores2)\n",
    "scores3 = sum(matrix[:, 2])\n",
    "print(scores3)\n",
    "scores4 = sum(matrix[:, 3])\n",
    "print(scores4)\n",
    "scores = sorted([scores1, scores2, scores3, scores4])\n",
    "print(scores)\n",
    "'''\n",
    "\n",
    "# column wise addition\n",
    "features = vectorizer.get_feature_names()\n",
    "scores = {}\n",
    "for i in range(len(matrix)):\n",
    "    # print(matrix[:, i])\n",
    "    scores[features[i]] = sum(matrix[:, i])\n",
    "print(sorted(scores.items()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## Word2Vec\n",
    "\n",
    "- Data Scientists have assigned a vector to each english word\n",
    "\n",
    "- This process of assignning vectors to each word is called Word2Vec\n",
    "\n",

    "- In ACS 4511, we will learn how they accomplished Word2Vec task\n",
=======
    "- In DS 2.4, we will learn how they accomplished Word2Vec task\n",
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
    "\n",
    "- Download this huge Word2Vec file: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "- Do not open the extracted file"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "## What is the property of vectors associated to each word in Word2Vec?\n",
    "\n",
    "- Words with similar meanings would be closer to each other in Euclidean Space\n",
    "\n",
    "- For example if $V_{pizza}$, $V_{food}$ and $V_{sport}$ represent the vector associated to pizza, food and sport then:\n",
    "\n",
    "${\\| V_{pizza} - V_{food}}\\|$ < ${\\| V_{pizza} - V_{sport}}\\|$"

   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acitivity: Obtain the vector associated to pizza in Glove"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('/Users/miladtoutounchian/Downloads/glove.840B.300d.txt', 'r') as f:\n",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acitivity: Obtain the vector associated to pizza in Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza\n",
      "[0.25734, 0.4834, 0.39895, -0.021904, -0.23251, 0.1912, -0.060446, -0.25761, -0.45211, 0.041514, -0.2691, -0.70659, -0.19061, 0.61703, -0.31782, 0.027941, -0.16662, -0.10881, -0.34464, 0.42024, 0.36226, 0.72459, -0.037924, -0.13019, 0.41046, -0.053523, 0.24423, 0.018026, 0.43282, -1.2634, -0.54086, 0.47269, 0.35893, -0.26779, -0.57371, 0.35586, -0.3969, -0.35332, -0.48882, 0.24765, 0.15628, 0.03886, 0.0079223, 0.54105, -0.13862, 0.32459, 1.0425, 0.12856, 0.036834, -0.22976, -0.087973, -0.69039, 0.35075, 0.56834, -0.19602, -0.2434, -0.075702, 0.37302, 0.14015, -0.24343, 0.79112, -0.25912, -0.017421, -0.46356, -0.12607, -0.37098, -0.23651, 0.50475, -0.30574, 0.28055, 0.52918, 0.15871, -0.098648, -0.40663, 0.13522, -0.23016, -0.15465, -0.10037, -0.06647, -0.35895, -0.12413, 0.44327, 0.082424, -0.44134, -0.14447, -0.48395, 0.29215, 0.24427, -0.32845, 0.054433, 0.2512, 0.13315, -0.16265, -0.12271, -0.0041962, 0.048386, -0.28681, 0.20425, -0.40364, 0.097275, 0.33175, -0.087691, 0.010024, -0.51279, -0.083069, -0.39199, 0.15068, 0.75919, -0.2137, 0.15024, 0.36299, 0.031102, 0.28151, -0.5998, 0.44464, -0.63282, -0.61203, 0.24946, -0.3671, -0.056996, -0.17517, 0.16251, 0.80415, -0.10598, -0.30048, 0.18238, 0.048485, 0.13027, -0.33109, -0.13229, 0.047343, 0.43838, -0.18593, -0.018344, 0.19721, -0.23306, 0.030151, 0.19396, -0.145, 0.381, 0.15014, 0.052432, -0.27918, -0.39125, -0.29462, 0.15047, -0.081706, 0.4011, -0.0575, -0.50655, -0.47707, 1.0189, 0.31265, -0.041707, -0.47167, -0.29949, -0.11954, 0.27206, -0.32978, -0.51524, 0.5026, 0.44518, -0.41282, 0.33215, -0.032643, 0.23382, 0.068028, -0.079137, 0.47821, -0.17514, 0.077763, 0.21428, -0.46747, 0.31344, -0.56925, 0.59784, 0.066899, 0.20827, 0.54411, -0.72478, -0.0035688, 0.22487, 0.35049, -0.040805, 0.11252, -0.16417, 0.28461, 0.43424, 0.34098, -0.27205, 0.64251, 0.77129, -0.24036, -0.12203, -0.18944, 0.12603, -0.85211, -0.22276, -0.43415, 0.2337, 0.41605, -0.66573, 1.1912, 0.2776, -0.80715, -0.23507, 0.74769, -0.0066615, 0.22775, -0.0070054, -0.39856, 0.22202, 0.43487, -0.55411, -0.6639, 0.13468, 0.20789, -0.17928, -0.20626, 0.73467, 0.54894, 0.40077, 0.063216, -0.026543, -0.72435, -0.61129, -0.079665, -0.63886, -0.27314, -0.2861, 0.26289, 0.48562, -0.13764, -0.078798, 0.36975, -0.055627, 1.1485, 0.039506, -0.89829, 0.23682, -0.36148, -0.11356, -0.072841, -0.79757, -0.49976, -0.21447, -0.049037, 0.39696, -0.17424, -0.41205, 1.1871, 0.5167, -0.059791, 0.71421, 0.1655, 0.33953, -0.10358, 0.29297, -0.26831, 0.1768, 0.3269, -0.42351, -0.11839, 0.16728, 0.06569, -0.43177, 0.28575, 0.39147, 0.49807, -0.13639, -0.6024, -0.50789, 0.052283, 0.3962, 0.86925, -0.096854, -1.1966, 0.042479, -1.2523, -0.12236, -0.12434, 0.31724, -0.28243, 0.18327, -0.080857, 0.14132, 0.55221, -0.27664, 0.31122, 0.075609, 0.22901, -0.0070232, -0.19509, 0.26924, -0.48834, -0.34159, 0.34529, 0.032231, -0.38957, 0.05093]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('Datasets/glove.6B/glove.6B.300d.txt', 'r') as f:\n",
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] == 'pizza':\n",
    "            print(sr[0])\n",
    "            print([float(i) for i in sr[1:]])\n",
    "            print(len([float(i) for i in sr[1:]]))\n",
    "            break"

   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pizza\n",
      "[0.0068727, -0.21634, 0.27831, -0.26192, 0.22884, 0.89332, 0.4131, 0.27377, 0.22652, 1.5041, -0.58059, 0.56083, -0.18432, 0.27738, -0.10709, -0.13519, 0.023817, 1.1765, -0.12659, 0.043173, 0.23242, -0.63213, 0.40228, -0.20605, 0.46381, -0.12991, -0.68031, -0.010371, 0.50033, -0.32266, 0.24053, 0.40178, 0.12051, -0.13791, 0.40821, 0.54735, -0.25946, 0.020254, 0.21249, 0.91965, -0.21202, 0.66568, 0.25879, -0.36124, -0.10977, 0.87492, -0.089425, 0.39184, -0.32589, -0.22331, -0.17504, 0.074762, 0.45271, 0.085476, -0.079526, -0.23986, -0.010322, 0.089974, 0.29794, 0.26672, -0.044288, -0.082716, 0.20801, 0.38404, 0.15281, -1.1292, -0.094527, 0.16901, -0.018155, 0.31023, -0.095716, 0.32587, -0.2225, -0.040376, -0.52201, -0.040547, -0.2473, 0.059596, 0.31592, 0.48751, 0.14681, -0.29337, 0.61309, -0.7844, -0.16297, 0.042847, 0.90914, 0.70536, -0.44725, -0.3035, -0.26998, -0.32488, 0.10539, -0.24494, -0.023413, 0.51872, -0.0060798, -0.039611, 0.28618, 0.17071, -0.661, -0.1303, 0.59381, 0.33792, -0.016678, -0.31536, 0.92849, -0.19661, 0.14412, 0.141, 0.095604, -0.65534, -0.66278, -0.068806, 0.57471, -0.34244, 0.30524, 0.070219, -0.31053, 0.25418, 0.16362, 0.48417, 0.15889, 0.20571, -0.24816, -0.52146, 0.85366, 0.029624, -0.20695, 0.68848, -0.19801, -0.55261, 0.25334, 0.23374, -0.47797, -0.58102, -0.30506, -0.24182, -0.089947, 0.020074, -2.442, -0.38229, 0.38005, 0.45891, -0.10147, -0.46439, -0.47909, 0.48057, 0.66937, 0.16773, 0.23094, -0.0037971, 0.11692, 0.19027, 0.22866, -0.10451, 0.16913, 0.1929, 0.21792, 0.3183, -0.69639, -0.039663, -0.034875, -0.34398, -0.033303, -0.44731, 0.39323, 0.28786, 0.41256, -0.042063, 0.053043, 0.032974, 0.13665, -0.47123, -0.59784, -0.15469, -0.043701, -0.28768, -0.5192, -0.81342, 0.28083, -0.20795, -0.0063995, -0.2165, -0.18462, -0.12112, 0.16446, 0.1074, -0.21256, -0.079728, -0.26936, 0.1213, -0.41473, -0.3929, 0.11391, 0.017356, 0.6225, 0.39374, 0.18043, 0.06208, -0.048457, -0.13303, -0.28215, 0.23984, 0.19951, 0.079811, -0.24321, 0.52115, 0.37684, -0.16641, 0.18813, 0.38081, -0.068178, 0.17925, 0.26455, -0.19848, 0.23375, -0.075531, -0.26779, 0.20576, -0.14164, 0.18145, -0.27216, -0.27441, 0.07846, -0.15033, -1.008, 0.010385, -0.42617, -0.2697, -0.1037, 0.23114, 0.31361, -0.64973, 0.081318, -0.20336, -0.21733, -0.47194, -0.22844, 0.3207, 0.47024, 0.19194, -0.38945, -0.53102, 0.30868, 0.4516, 0.35045, -0.41879, -0.6142, -0.25174, 0.1445, -0.37202, -0.29062, -0.24497, 0.11433, 0.51326, -0.10476, 0.070229, -0.33251, -0.26181, -0.22115, -0.098211, -0.8274, -0.73995, -0.2146, 0.61523, -0.36608, -0.043749, -1.0097, 0.19351, -0.54799, 0.28998, -0.07631, 0.075785, -0.63011, 0.084629, -0.021395, -0.060536, 0.48363, 0.16488, 0.42662, -0.1786, 0.14382, 0.3153, 0.017293, 0.6706, 0.49765, 0.34787, -0.62071, 0.20983, 0.71446, 0.071448, -0.14597, 0.50002, -0.42449, -0.3517, 0.10134, -0.5875, 0.11043, 0.47559]\n",
      "300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activity: Obtain the vectors associated to pizza, food and sport in Glove"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('/Users/miladtoutounchian/Downloads/glove.840B.300d.txt', 'r') as f:\n",
=======
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the vectors associated to pizza, food and sport in Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'food': [0.38544, 0.34247, 0.29599, -0.262, 0.037383, 0.45544, 0.49097, 0.11481, -0.11437, -1.9067, 0.035563, -1.1094, -0.26512, 0.64418, -0.031008, -0.3513, -0.0010547, 0.074658, -0.30369, -0.28188, -0.34342, 0.36205, 0.71009, 0.30243, 0.070325, 0.29492, -0.16233, 0.30998, 0.13705, 0.11847, -0.68642, 0.43305, -0.61518, 0.23643, -0.84174, 0.14667, -0.096616, -0.20908, -0.42296, -0.27254, -0.79343, -0.62781, 0.64804, 0.11541, -0.33486, -0.14101, 0.12864, -0.25123, -0.26515, 0.30876, -0.063111, 0.17893, 0.41197, 0.019621, -0.15406, 0.17542, 0.39268, 0.088817, 0.018012, -0.22508, -0.31832, 0.022296, 0.59453, 0.056538, -0.72464, -0.31751, -0.3865, 0.33806, -0.16237, -0.0076169, 0.52897, 0.14628, -0.22458, -0.66751, 0.23012, -0.068667, 0.4668, 0.2204, -0.38321, -0.18401, 0.36828, 0.085637, -0.28836, 0.43894, 0.1579, -1.1443, -0.17327, -0.0027353, -0.32621, -0.2411, -0.14597, 0.061719, -0.3021, -0.16319, 0.0025848, 0.26203, 0.045155, -0.019056, -0.48923, 0.062269, 0.1214, 0.054817, 0.01157, -0.16724, -0.30459, -0.53924, -0.21938, 0.049682, -0.19532, 0.024412, 0.18323, -0.22832, -0.375, -0.25533, 0.24311, 0.008097, 0.044543, 0.41836, 0.26278, 0.20927, -0.45486, 0.14258, 0.36823, 0.64177, 0.049307, -0.038022, 0.033907, -0.1173, 0.40365, 0.23042, 0.20191, -0.099931, 0.60634, -0.069024, -0.11417, -0.11435, 0.1171, 0.25884, -0.059129, 1.027, -0.065444, 0.33082, 0.41195, -0.51409, -0.46449, 0.49719, 0.18368, 0.11482, 0.20175, -0.4858, -0.11395, 0.24271, 0.53452, -0.17599, -0.18241, 0.085407, -0.27614, -0.33535, 0.13731, -0.38903, 0.47308, -0.28132, 0.29753, -0.16403, -0.51195, 0.25532, 0.26516, -0.6139, 0.013088, 0.35948, 0.16281, 0.31889, -0.57797, 0.25247, -0.55389, 0.56864, 0.089668, -0.20646, 0.10619, -0.12391, -0.40631, -0.29375, -0.6114, -0.21382, 0.077146, 0.22001, 0.33794, 0.11534, 0.22742, -0.25098, -0.15659, 0.7597, -1.1835, -0.37791, -0.34801, 0.29379, -0.48425, 0.175, 0.19507, 0.84789, -0.1802, -0.14255, 0.61267, 0.48842, -0.18246, 0.15696, 0.29159, -0.33145, 0.065447, -0.2671, -0.49741, -0.35313, -0.08501, 0.13289, -0.058364, 0.70297, 0.21803, -0.23166, 0.23356, 0.45469, 0.77361, -0.25131, -0.05397, -0.033968, -0.033857, -0.2106, 0.26651, 0.40503, 0.21139, 0.31596, 0.23324, 0.42179, -0.42393, 0.29181, 0.17072, 0.49736, 0.39993, 0.076354, -0.59329, -0.037345, -0.39826, -0.28424, -0.026921, -0.31003, -1.46, 0.012187, 0.19133, 0.08535, -0.016125, 0.26185, 0.52257, 0.11262, -0.1481, 0.15431, 0.48882, 0.416, -0.53778, -0.51524, -0.27682, 0.31711, -0.078578, -0.86162, -0.51523, -0.97632, 0.21927, -0.00083264, -0.0027921, 0.25754, 0.29383, -0.20229, -0.61117, 0.31172, -0.21503, 0.038843, 0.26046, -0.1239, -2.3409, 0.30863, -0.29139, -0.09166, -0.24405, 0.10426, 0.23199, 0.23967, -0.18697, 0.14248, 0.71032, -0.33381, 0.11111, -0.10267, 0.21123, -0.18594, -0.079114, -0.11809, -0.08642, 0.1409, -0.27209, -0.49944, -0.2751, -0.61361], 'sport': [0.34566, 0.15934, 0.48444, -0.13693, 0.18737, 0.2678, -0.39159, 0.4931, -0.76111, -1.4586, 0.41475, 0.55837, 0.021504, 0.28509, -0.30284, 0.021432, 0.071542, 0.53333, 0.18084, -0.40818, -0.37935, 0.86781, 0.4492, 0.67524, 0.052925, -0.42635, 0.46103, 0.031358, 0.5166, -0.081332, 0.35399, -0.53411, -0.22646, -0.091881, -0.5428, 0.61143, 0.67188, 0.079147, -0.21608, 0.2817, 0.22489, 0.0087532, 0.096962, -0.19739, 0.61631, 0.19901, 0.37232, 0.13627, 0.18799, 0.35549, -0.74315, -0.08624, 0.1883, -0.53688, 0.082768, 0.78362, -0.31835, -0.21211, -0.023984, 0.0095728, 0.28296, 0.30896, -0.38585, -0.55332, -0.66063, 0.30262, -0.65959, 0.25509, -0.55906, -0.3507, -0.11521, 0.32024, -0.25448, 0.12392, -0.22941, -0.30697, -0.073869, -0.021054, 0.26082, 0.45367, 0.32809, 0.56492, 0.067392, -0.54504, -0.45747, 0.29705, -0.007364, -0.15747, -0.19674, 0.44562, 0.10822, -0.010847, -0.020063, -0.54242, 0.85393, -0.098667, 0.22144, -0.1058, 0.08902, 0.059909, 0.17442, 0.34239, 0.071011, 0.32127, 0.099133, 0.60742, 0.52472, -0.13034, -0.10823, 0.16208, 0.30687, -0.079381, 0.046322, -0.96637, -0.034772, -0.032899, 0.44984, -0.0086, -0.24193, 0.067582, -0.13938, 0.19137, 0.46692, 0.58191, -0.20529, -0.29932, -0.19122, 0.47751, 0.011554, 0.016327, 0.14571, -0.29702, -0.22549, 0.078491, -0.2856, 0.027681, -0.050709, 0.08904, -0.10603, 0.5987, 0.17281, 0.0021526, 0.93064, -0.057695, 0.17412, -0.31447, 0.0025599, -0.079155, -0.08038, 0.62715, 0.62819, 0.25948, -0.25359, -0.38077, 0.30185, -0.93266, -0.02277, 0.40116, -0.0079393, -0.029146, 0.2834, -0.42381, -0.75231, -0.03341, 0.18793, -0.80745, -0.1471, 0.12451, 0.16207, -0.83302, -0.48239, 0.12213, -1.0567, 0.60332, 0.25437, -0.12537, 0.28882, -0.13624, 0.16769, 0.82878, 0.33491, 0.57352, 0.0038668, 0.052082, 0.87144, -0.40841, 0.0081564, 0.0021284, -0.33046, -0.16384, -0.31893, -0.16997, -0.24397, 0.24522, 0.19511, -0.17615, -0.12781, 0.61104, 0.62262, -0.28578, 1.032, -0.24093, -0.072303, 0.065576, -0.45258, -0.15914, 0.27673, 0.046784, -0.23509, 0.078567, 0.18001, 0.023338, -0.7807, 0.48395, -0.13503, 0.15531, 0.12585, 0.14729, -0.3931, -0.44495, -0.0121, -0.49026, 0.33196, -0.63298, 0.49953, -0.25245, -0.30707, 0.30539, -0.0075252, 0.1769, 0.20692, -0.59478, 0.3011, -0.38093, 0.36627, -0.05798, 0.35727, 0.65025, -0.23389, -0.056722, 0.35972, -0.15963, 0.15001, -0.056637, -0.63519, 0.13256, -0.4007, -0.19513, -0.27042, 0.33505, -0.15308, -0.058018, -0.025477, -0.4279, 0.013337, -0.26202, -0.012633, -0.34509, 0.14835, -0.63398, -0.15411, -0.82738, 0.37643, 0.11571, 0.39404, -0.36529, -0.3185, 0.35226, -0.20441, 0.10508, -0.022458, 0.32689, -0.22491, -0.14179, 0.79285, 0.3091, -1.7894, -0.24364, 0.33151, 0.60022, -0.088763, 0.11163, -0.1362, 0.32127, 0.017934, -0.6352, -0.61595, -0.24006, 0.13802, 0.36619, 0.19734, 0.35701, -0.42228, -0.25242, -0.050651, -0.041129, 0.15092, 0.22084, 0.52252, -0.27224], 'pizza': [0.25734, 0.4834, 0.39895, -0.021904, -0.23251, 0.1912, -0.060446, -0.25761, -0.45211, 0.041514, -0.2691, -0.70659, -0.19061, 0.61703, -0.31782, 0.027941, -0.16662, -0.10881, -0.34464, 0.42024, 0.36226, 0.72459, -0.037924, -0.13019, 0.41046, -0.053523, 0.24423, 0.018026, 0.43282, -1.2634, -0.54086, 0.47269, 0.35893, -0.26779, -0.57371, 0.35586, -0.3969, -0.35332, -0.48882, 0.24765, 0.15628, 0.03886, 0.0079223, 0.54105, -0.13862, 0.32459, 1.0425, 0.12856, 0.036834, -0.22976, -0.087973, -0.69039, 0.35075, 0.56834, -0.19602, -0.2434, -0.075702, 0.37302, 0.14015, -0.24343, 0.79112, -0.25912, -0.017421, -0.46356, -0.12607, -0.37098, -0.23651, 0.50475, -0.30574, 0.28055, 0.52918, 0.15871, -0.098648, -0.40663, 0.13522, -0.23016, -0.15465, -0.10037, -0.06647, -0.35895, -0.12413, 0.44327, 0.082424, -0.44134, -0.14447, -0.48395, 0.29215, 0.24427, -0.32845, 0.054433, 0.2512, 0.13315, -0.16265, -0.12271, -0.0041962, 0.048386, -0.28681, 0.20425, -0.40364, 0.097275, 0.33175, -0.087691, 0.010024, -0.51279, -0.083069, -0.39199, 0.15068, 0.75919, -0.2137, 0.15024, 0.36299, 0.031102, 0.28151, -0.5998, 0.44464, -0.63282, -0.61203, 0.24946, -0.3671, -0.056996, -0.17517, 0.16251, 0.80415, -0.10598, -0.30048, 0.18238, 0.048485, 0.13027, -0.33109, -0.13229, 0.047343, 0.43838, -0.18593, -0.018344, 0.19721, -0.23306, 0.030151, 0.19396, -0.145, 0.381, 0.15014, 0.052432, -0.27918, -0.39125, -0.29462, 0.15047, -0.081706, 0.4011, -0.0575, -0.50655, -0.47707, 1.0189, 0.31265, -0.041707, -0.47167, -0.29949, -0.11954, 0.27206, -0.32978, -0.51524, 0.5026, 0.44518, -0.41282, 0.33215, -0.032643, 0.23382, 0.068028, -0.079137, 0.47821, -0.17514, 0.077763, 0.21428, -0.46747, 0.31344, -0.56925, 0.59784, 0.066899, 0.20827, 0.54411, -0.72478, -0.0035688, 0.22487, 0.35049, -0.040805, 0.11252, -0.16417, 0.28461, 0.43424, 0.34098, -0.27205, 0.64251, 0.77129, -0.24036, -0.12203, -0.18944, 0.12603, -0.85211, -0.22276, -0.43415, 0.2337, 0.41605, -0.66573, 1.1912, 0.2776, -0.80715, -0.23507, 0.74769, -0.0066615, 0.22775, -0.0070054, -0.39856, 0.22202, 0.43487, -0.55411, -0.6639, 0.13468, 0.20789, -0.17928, -0.20626, 0.73467, 0.54894, 0.40077, 0.063216, -0.026543, -0.72435, -0.61129, -0.079665, -0.63886, -0.27314, -0.2861, 0.26289, 0.48562, -0.13764, -0.078798, 0.36975, -0.055627, 1.1485, 0.039506, -0.89829, 0.23682, -0.36148, -0.11356, -0.072841, -0.79757, -0.49976, -0.21447, -0.049037, 0.39696, -0.17424, -0.41205, 1.1871, 0.5167, -0.059791, 0.71421, 0.1655, 0.33953, -0.10358, 0.29297, -0.26831, 0.1768, 0.3269, -0.42351, -0.11839, 0.16728, 0.06569, -0.43177, 0.28575, 0.39147, 0.49807, -0.13639, -0.6024, -0.50789, 0.052283, 0.3962, 0.86925, -0.096854, -1.1966, 0.042479, -1.2523, -0.12236, -0.12434, 0.31724, -0.28243, 0.18327, -0.080857, 0.14132, 0.55221, -0.27664, 0.31122, 0.075609, 0.22901, -0.0070232, -0.19509, 0.26924, -0.48834, -0.34159, 0.34529, 0.032231, -0.38957, 0.05093]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # words = ['pizza', 'food', 'sport']\\n    words_vecs = {}\\n    for c, r in enumerate(f):\\n        sr = r.split()\\n        if sr[0] == 'pizza':\\n           words_vecs['pizza'] = [float(i) for i in sr[1:]]\\n        elif sr[0] == 'food':\\n           words_vecs['food'] = [float(i) for i in sr[1:]]\\n        elif sr[0] == 'sport':\\n           words_vecs['sport'] = [float(i) for i in sr[1:]]\\n        \\n    print(words_vecs)\\n    # verify that the pizza and food are closer together than pizza and sport, using Euclidean distance\\n    distance_p_f = np.linalg.norm( words_vecs['pizza'], words_vecs['food'])\\n    print(distance_p_f)\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "with codecs.open('Datasets/glove.6B/glove.6B.300d.txt', 'r') as f:\n",
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
    "    ls = {}\n",
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] in ['pizza', 'food', 'sport']:\n",
    "            ls[sr[0]] =[float(i) for i in sr[1:]]\n",
    "        if len(ls) == 3:\n",
    "            break\n",
    "\n",

    "print(ls) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'food': [-0.43512, 0.028351, 0.4911, -0.35168, -0.11578, 1.0369, -0.09755, 0.086624, -0.1789, 2.4555, -1.2798, 0.021074, -0.03225, 0.094673, -0.14, -0.52143, 0.00066447, 1.8051, -0.22604, 0.33227, 0.00041163, 0.062654, 0.14973, -0.5026, 0.089701, -0.26908, -0.083594, -0.16677, -0.17036, -0.32049, -0.23586, -0.40395, 0.32683, -0.21712, 0.098576, 0.47552, 0.092994, -0.061034, 0.12673, 0.60856, -0.0067936, -0.21831, 0.021751, -0.24858, -0.035244, 0.13692, -0.37109, 0.54421, 0.040017, 0.13992, 0.039967, -0.31745, 0.24408, -0.2355, 0.24884, -0.31929, 0.11282, -0.010198, -0.050538, -0.1155, 0.30273, -0.61441, 0.016135, 0.010675, 0.15108, -1.1759, 0.097104, 0.071706, 0.19795, 0.27253, -0.22122, 0.64478, -0.066252, -0.29403, 0.16281, -0.0078554, -0.14986, -0.11364, 0.36459, 0.13723, 0.46612, 0.26157, 0.0065022, -0.67068, -0.075247, -0.50802, -0.049202, 0.90222, -0.30085, 0.15453, -0.44762, -0.30997, -0.14006, -0.48079, 0.07838, -0.20951, -0.07558, -0.37064, 0.48714, -0.31549, -0.51954, -0.23939, -0.066667, 0.18613, -0.0022506, -1.1914, 0.88962, 0.077849, -0.028469, -0.20316, 0.1663, -0.51348, -0.5587, -0.23375, -0.053809, -0.22482, -0.16111, -0.055308, 0.25306, -0.26012, -0.44041, 0.45938, 0.2086, -0.37273, 0.18066, -0.68302, 0.6074, -0.43613, 0.21322, 0.080519, 0.23692, -0.82568, 0.60825, 0.28487, -0.21523, -0.25527, -0.02536, -0.20474, 0.17836, -0.46982, -1.5028, -0.13935, 0.63359, 0.077543, 0.23253, -0.9455, -0.31292, 0.1868, -0.15495, 0.044739, 0.039165, 0.25441, 0.3317, -0.072885, 0.26937, -0.46139, 0.67444, 0.040953, 0.17357, 0.24625, 0.11436, -0.019437, 0.084576, -0.25671, -0.19088, -0.0097901, 0.4067, -0.52662, 0.33074, -0.016063, 0.50736, -0.078741, -0.10957, -0.16075, -0.57401, 0.32421, 0.26512, 0.22437, 0.168, 0.0083381, 0.29091, -0.8531, -0.10966, 0.012598, 0.19428, -0.34592, 0.15497, 0.11221, -0.019593, -0.51683, -0.27562, -0.29003, -0.29849, -0.74871, -0.43796, 0.53964, 0.25437, 0.43718, 0.56013, -0.24569, -0.026945, 0.35646, 0.15037, 0.10629, 0.31965, 0.35652, 0.029006, 0.83085, 0.78779, -0.58642, -0.078122, 0.19765, -0.14726, -0.13157, -0.068822, -0.30101, 0.32966, -0.19465, -0.15736, 0.16771, -0.39267, 0.31687, 0.080543, -0.021005, -0.028093, -0.0086245, -0.11506, 0.078586, -0.43331, 0.15771, -0.30605, -0.32882, 0.18208, -0.39534, 0.33031, -0.099457, -0.16041, 0.057775, 0.20208, -0.3808, -0.23455, -0.025349, -0.23527, -0.081126, 0.035611, 0.56273, -0.096986, -0.38146, -0.62962, -0.20775, 0.05543, 0.44946, -0.27455, -0.11277, 0.31322, 0.71544, 0.022552, 0.0783, -0.25574, -0.23078, -0.76146, -0.13497, -0.474, -0.11224, 0.11929, 0.45973, -0.21328, -0.039544, -0.11253, -0.060995, -0.52906, 0.18361, 0.059157, -0.31468, 0.10018, 0.43707, -0.064725, 0.50211, 0.29269, 0.8572, -0.22293, 0.11703, -0.036008, -0.30947, -0.069151, 0.43019, 0.67241, -0.083894, -0.2771, 0.1445, 0.26701, 0.32489, -0.077239, 0.078217, -0.28737, 0.30253, 0.21972, -0.47151, 0.4301, 0.36573], 'sport': [0.61275, 0.31162, 0.27068, -0.22297, 0.45731, 0.016208, 0.22091, 0.12843, -0.43509, 1.8299, -0.60721, 0.060513, 0.25038, 0.39679, 0.46771, -0.13166, -0.11571, 0.7405, 0.26475, -0.11693, -0.64858, -0.54887, 0.54541, -0.20667, -0.086033, 0.27114, -0.1618, 0.22554, -0.17955, 0.36903, 0.12691, -0.1174, 0.019318, -0.28953, 0.30217, -0.47576, 0.54093, -0.38579, -0.21052, 0.4893, -0.15147, 0.28609, 0.22013, 0.75681, -0.14469, -0.16423, -0.095192, 0.63646, 0.2875, 0.088499, -0.21929, 0.10507, 0.41082, -0.28774, 0.1258, 0.063986, 0.44362, 0.34902, 0.19372, 0.16683, -0.12552, 0.36517, 0.31794, 0.2044, -0.15177, -0.18454, 0.078573, -0.28761, -0.2069, -0.36376, -0.52133, -0.48128, 0.15204, 0.15267, -0.37969, 0.14952, -0.014321, 0.28997, -0.28155, 0.4166, -0.35878, -0.70023, -0.17649, 0.39382, 0.1224, 0.18871, -0.26526, 0.91397, -0.01213, -0.055295, -0.11003, 0.20884, -0.037053, 0.01181, 0.10168, -0.62347, -0.0086453, -0.065524, 0.4229, 0.28113, -0.12605, -0.14138, -0.27168, -0.17355, -0.099353, -1.1769, 0.23814, 0.37717, 0.13348, 0.18683, -0.10739, -0.55708, -0.2436, -0.17149, -0.062647, -0.060539, 0.038614, -0.15553, 0.42478, 0.055208, 0.060124, -0.0488, -0.31571, -0.49472, 0.12172, 0.59352, -0.18675, -0.0017853, 0.5732, -0.16613, 0.47102, 0.019576, -0.38946, -0.61033, 0.35581, -0.43863, -0.35678, -0.54695, 0.19365, 0.33768, -1.7134, -0.025204, 0.92273, 0.27697, 0.4186, -0.14367, 0.65432, 0.065611, -0.17391, 0.35995, -0.49654, 0.38485, 0.46463, 0.17546, -0.017041, -0.07243, -0.14917, 0.20194, -0.28059, 0.059065, 0.32861, -0.55298, 0.5258, -0.57452, 0.34638, -0.0487, -0.385, -0.10107, -0.18656, -0.32187, -0.48726, -0.043128, -0.2229, 0.088367, 0.2682, -0.051919, -0.24149, 0.14255, 0.10829, 0.27343, -0.039065, 0.25164, 0.1256, 0.032913, -0.47683, -0.17763, 0.25448, 0.60327, -0.10467, -0.28146, 0.254, -0.25732, 0.041916, -0.63216, -0.10634, 0.30662, 0.40009, -0.574, 0.39424, 0.58208, 0.37425, 0.31072, 0.43803, 0.0041596, -0.6017, -0.090444, 0.23195, 0.0064566, -0.43496, -0.30735, -0.3633, 0.10456, -0.11538, -0.24502, -0.090916, 0.42796, -0.12982, 0.23451, -0.72916, 0.025435, 0.42421, 0.095135, 0.09271, -0.42076, -0.76232, 0.094191, -0.16968, 0.050921, 0.86174, 0.56093, -0.45083, 0.18556, -0.43674, 0.14425, -0.22978, -0.11217, -0.40731, 0.35943, 0.039032, 0.71693, -0.35826, -0.41117, 0.37001, -0.0030921, -0.42987, 0.24203, -0.15659, -0.15211, -0.61453, 0.53476, 0.61175, -0.47458, -0.36237, -0.045465, -0.054131, 0.28169, 0.089874, -0.047726, -0.23881, 0.34993, 0.70692, 0.2221, -0.11816, -0.00085544, 0.017349, 0.0064164, 0.058943, 0.19897, -0.066186, -0.037683, -0.44109, -0.43301, 0.025892, -0.033744, -0.08068, 0.1622, 0.43503, 0.25968, -0.20914, -0.048581, -0.48503, -0.31875, 0.075417, 0.52741, -0.10098, -0.38519, -0.16721, -0.038992, -0.11484, -0.46317, -0.519, -0.48945, -0.16657, -1.4382, 0.031249, 0.12955, -0.15718, -0.5244, 0.38711, 0.20144], 'pizza': [0.0068727, -0.21634, 0.27831, -0.26192, 0.22884, 0.89332, 0.4131, 0.27377, 0.22652, 1.5041, -0.58059, 0.56083, -0.18432, 0.27738, -0.10709, -0.13519, 0.023817, 1.1765, -0.12659, 0.043173, 0.23242, -0.63213, 0.40228, -0.20605, 0.46381, -0.12991, -0.68031, -0.010371, 0.50033, -0.32266, 0.24053, 0.40178, 0.12051, -0.13791, 0.40821, 0.54735, -0.25946, 0.020254, 0.21249, 0.91965, -0.21202, 0.66568, 0.25879, -0.36124, -0.10977, 0.87492, -0.089425, 0.39184, -0.32589, -0.22331, -0.17504, 0.074762, 0.45271, 0.085476, -0.079526, -0.23986, -0.010322, 0.089974, 0.29794, 0.26672, -0.044288, -0.082716, 0.20801, 0.38404, 0.15281, -1.1292, -0.094527, 0.16901, -0.018155, 0.31023, -0.095716, 0.32587, -0.2225, -0.040376, -0.52201, -0.040547, -0.2473, 0.059596, 0.31592, 0.48751, 0.14681, -0.29337, 0.61309, -0.7844, -0.16297, 0.042847, 0.90914, 0.70536, -0.44725, -0.3035, -0.26998, -0.32488, 0.10539, -0.24494, -0.023413, 0.51872, -0.0060798, -0.039611, 0.28618, 0.17071, -0.661, -0.1303, 0.59381, 0.33792, -0.016678, -0.31536, 0.92849, -0.19661, 0.14412, 0.141, 0.095604, -0.65534, -0.66278, -0.068806, 0.57471, -0.34244, 0.30524, 0.070219, -0.31053, 0.25418, 0.16362, 0.48417, 0.15889, 0.20571, -0.24816, -0.52146, 0.85366, 0.029624, -0.20695, 0.68848, -0.19801, -0.55261, 0.25334, 0.23374, -0.47797, -0.58102, -0.30506, -0.24182, -0.089947, 0.020074, -2.442, -0.38229, 0.38005, 0.45891, -0.10147, -0.46439, -0.47909, 0.48057, 0.66937, 0.16773, 0.23094, -0.0037971, 0.11692, 0.19027, 0.22866, -0.10451, 0.16913, 0.1929, 0.21792, 0.3183, -0.69639, -0.039663, -0.034875, -0.34398, -0.033303, -0.44731, 0.39323, 0.28786, 0.41256, -0.042063, 0.053043, 0.032974, 0.13665, -0.47123, -0.59784, -0.15469, -0.043701, -0.28768, -0.5192, -0.81342, 0.28083, -0.20795, -0.0063995, -0.2165, -0.18462, -0.12112, 0.16446, 0.1074, -0.21256, -0.079728, -0.26936, 0.1213, -0.41473, -0.3929, 0.11391, 0.017356, 0.6225, 0.39374, 0.18043, 0.06208, -0.048457, -0.13303, -0.28215, 0.23984, 0.19951, 0.079811, -0.24321, 0.52115, 0.37684, -0.16641, 0.18813, 0.38081, -0.068178, 0.17925, 0.26455, -0.19848, 0.23375, -0.075531, -0.26779, 0.20576, -0.14164, 0.18145, -0.27216, -0.27441, 0.07846, -0.15033, -1.008, 0.010385, -0.42617, -0.2697, -0.1037, 0.23114, 0.31361, -0.64973, 0.081318, -0.20336, -0.21733, -0.47194, -0.22844, 0.3207, 0.47024, 0.19194, -0.38945, -0.53102, 0.30868, 0.4516, 0.35045, -0.41879, -0.6142, -0.25174, 0.1445, -0.37202, -0.29062, -0.24497, 0.11433, 0.51326, -0.10476, 0.070229, -0.33251, -0.26181, -0.22115, -0.098211, -0.8274, -0.73995, -0.2146, 0.61523, -0.36608, -0.043749, -1.0097, 0.19351, -0.54799, 0.28998, -0.07631, 0.075785, -0.63011, 0.084629, -0.021395, -0.060536, 0.48363, 0.16488, 0.42662, -0.1786, 0.14382, 0.3153, 0.017293, 0.6706, 0.49765, 0.34787, -0.62071, 0.20983, 0.71446, 0.071448, -0.14597, 0.50002, -0.42449, -0.3517, 0.10134, -0.5875, 0.11043, 0.47559]}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acitivty: Show that the vector of pizza is closer to vector of food than vector of sport"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
=======
    "print(ls)\n",
    "''' # words = ['pizza', 'food', 'sport']\n",
    "    words_vecs = {}\n",
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] == 'pizza':\n",
    "           words_vecs['pizza'] = [float(i) for i in sr[1:]]\n",
    "        elif sr[0] == 'food':\n",
    "           words_vecs['food'] = [float(i) for i in sr[1:]]\n",
    "        elif sr[0] == 'sport':\n",
    "           words_vecs['sport'] = [float(i) for i in sr[1:]]\n",
    "        \n",
    "    print(words_vecs)\n",
    "    # verify that the pizza and food are closer together than pizza and sport, using Euclidean distance\n",
    "    distance_p_f = np.linalg.norm( words_vecs['pizza'], words_vecs['food'])\n",
    "    print(distance_p_f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acitivty: Show that the vector of pizza is closer to vector of food than vector of sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.63426225303502"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
   "source": [
    "import numpy as np\n",
    "\n",
    "np.linalg.norm(np.array(ls['pizza']) - np.array(ls['food']))"

   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.312737677708336"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "np.linalg.norm(np.array(ls['pizza']) - np.array(ls['sport']))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.817056623492523"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "np.linalg.norm(np.array(ls['food']) - np.array(ls['sport']))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.303718155175721"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.341560240989656"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array(ls['pizza']) - np.array(ls['sport']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.896379012366626"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array(ls['food']) - np.array(ls['sport']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [3, 4], [1, 2], [0, 0]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort a dictionary by its values\n",
    "x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n",
    "y = {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "#{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n",
    "z = [sorted([value, key]) for key, value in x.items()]\n",
    "z"
   ]
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "source": [],
   "outputs": [],
   "metadata": {}
=======
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

   "version": "3.6.5"
=======
   "version": "3.7.6"
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2

}
=======
}
>>>>>>> 0985223516d371741ba5aef0e183a8b1c08abde1
