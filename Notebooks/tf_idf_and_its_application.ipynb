{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- How we can exctract keywords from corpus (collections of texts) using TF-IDF\n",
    "\n",
    "- Explain what is TF-IDF\n",
    "\n",
    "- Applications of keywords exctraction algorithm and Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: What are the pre-processings to apply a machine learning algorithm on text data?\n",
    "\n",
    "1. The text must be parsed to words, called tokenization\n",
    "\n",
    "2. Then the words need to be encoded as integers or floating point values\n",
    "\n",
    "3. scikit-learn library offers easy-to-use tools to perform both tokenization and feature extraction of text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is TF-IDF Vectorizer?\n",
    "\n",
    "- Word counts are a good starting point, but are very basic\n",
    "\n",
    "An alternative is to calculate word frequencies, and by far the most popular method is called TF-IDF. \n",
    "\n",
    "**Term Frequency**: This summarizes how often a given word appears within a document\n",
    "\n",
    "**Inverse Document Frequency**: This downscales words that appear a lot across documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitive idea behind TF-IDF:\n",
    "    \n",
    "- If a word appears frequently in a document, it's important. Give the word a high score\n",
    "\n",
    "- But if a word appears in many documents, it's not a unique identifier. Give the word a low score\n",
    "\n",
    "<img src=\"Images/tfidf_slide.png\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the keywords from TF-IDF\n",
    "\n",
    "1- First obtain the TF-IDF matrix for given corpus\n",
    "\n",
    "2- Do column-wise addition\n",
    "\n",
    "3- Sort the score from highest to lowest\n",
    "\n",
    "4- Return the associated words based on step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.78528828 0.         0.6191303  0.        ]\n",
      " [0.70710678 0.         0.         0.         0.70710678]\n",
      " [0.53256952 0.         0.         0.65782931 0.53256952]\n",
      " [0.36626037 0.         0.57381765 0.         0.73252075]]\n",
      "[('bright', 1.605936677684143), ('bule', 0.7852882757103967), ('shining', 0.5738176501168697), ('sky', 1.27695960978985)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def keyword_sklearn(docs, k):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "    print(tfidf_matrix.toarray())\n",
    "    print(vectorizer.get_feature_names())\n",
    "    tfidf_scores = np.sum(tfidf_matrix, axis=0)\n",
    "    tfidf_scores = np.ravel(tfidf_scores)\n",
    "    return sorted(dict(zip(vectorizer.get_feature_names(), tfidf_scores)).items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "documnets = ['The sky is bule', 'The sun is bright', 'The sun in the sky is bright', 'we can see the shining sun, the bright sun']\n",
    "\n",
    "# print(keyword_sklearn(documnets, 3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "docs = ['The sky is bule', 'The sun is bright', 'The sun in the sky is bright', 'we can see the shining sun, the bright sun']\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "mat = vectorizer.fit_transform(docs)\n",
    "matrix = mat.toarray()\n",
    "print(matrix)\n",
    "# print(vectorizer.get_feature_names())  # which types of words do we have, after dropping stop words\n",
    "\n",
    "\n",
    "'''# column wise addition\n",
    "scores1 = sum(matrix[:, 0])\n",
    "print(scores1)\n",
    "scores2 = sum(matrix[:, 1])\n",
    "print(scores2)\n",
    "scores3 = sum(matrix[:, 2])\n",
    "print(scores3)\n",
    "scores4 = sum(matrix[:, 3])\n",
    "print(scores4)\n",
    "scores = sorted([scores1, scores2, scores3, scores4])\n",
    "print(scores)\n",
    "'''\n",
    "\n",
    "# column wise addition\n",
    "features = vectorizer.get_feature_names()\n",
    "scores = {}\n",
    "for i in range(len(matrix)):\n",
    "    # print(matrix[:, i])\n",
    "    scores[features[i]] = sum(matrix[:, i])\n",
    "print(sorted(scores.items()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "- Data Scientists have assigned a vector to each english word\n",
    "\n",
    "- This process of assignning vectors to each word is called Word2Vec\n",
    "\n",
    "- In DS 2.4, we will learn how they accomplished Word2Vec task\n",
    "\n",
    "- Download this huge Word2Vec file: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "- Do not open the extracted file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the property of vectors associated to each word in Word2Vec?\n",
    "\n",
    "- Words with similar meanings would be closer to each other in Euclidean Space\n",
    "\n",
    "- For example if $V_{pizza}$, $V_{food}$ and $V_{sport}$ represent the vector associated to pizza, food and sport then:\n",
    "\n",
    "${\\| V_{pizza} - V_{food}}\\|$ < ${\\| V_{pizza} - V_{sport}}\\|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acitivity: Obtain the vector associated to pizza in Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza\n",
      "[0.25734, 0.4834, 0.39895, -0.021904, -0.23251, 0.1912, -0.060446, -0.25761, -0.45211, 0.041514, -0.2691, -0.70659, -0.19061, 0.61703, -0.31782, 0.027941, -0.16662, -0.10881, -0.34464, 0.42024, 0.36226, 0.72459, -0.037924, -0.13019, 0.41046, -0.053523, 0.24423, 0.018026, 0.43282, -1.2634, -0.54086, 0.47269, 0.35893, -0.26779, -0.57371, 0.35586, -0.3969, -0.35332, -0.48882, 0.24765, 0.15628, 0.03886, 0.0079223, 0.54105, -0.13862, 0.32459, 1.0425, 0.12856, 0.036834, -0.22976, -0.087973, -0.69039, 0.35075, 0.56834, -0.19602, -0.2434, -0.075702, 0.37302, 0.14015, -0.24343, 0.79112, -0.25912, -0.017421, -0.46356, -0.12607, -0.37098, -0.23651, 0.50475, -0.30574, 0.28055, 0.52918, 0.15871, -0.098648, -0.40663, 0.13522, -0.23016, -0.15465, -0.10037, -0.06647, -0.35895, -0.12413, 0.44327, 0.082424, -0.44134, -0.14447, -0.48395, 0.29215, 0.24427, -0.32845, 0.054433, 0.2512, 0.13315, -0.16265, -0.12271, -0.0041962, 0.048386, -0.28681, 0.20425, -0.40364, 0.097275, 0.33175, -0.087691, 0.010024, -0.51279, -0.083069, -0.39199, 0.15068, 0.75919, -0.2137, 0.15024, 0.36299, 0.031102, 0.28151, -0.5998, 0.44464, -0.63282, -0.61203, 0.24946, -0.3671, -0.056996, -0.17517, 0.16251, 0.80415, -0.10598, -0.30048, 0.18238, 0.048485, 0.13027, -0.33109, -0.13229, 0.047343, 0.43838, -0.18593, -0.018344, 0.19721, -0.23306, 0.030151, 0.19396, -0.145, 0.381, 0.15014, 0.052432, -0.27918, -0.39125, -0.29462, 0.15047, -0.081706, 0.4011, -0.0575, -0.50655, -0.47707, 1.0189, 0.31265, -0.041707, -0.47167, -0.29949, -0.11954, 0.27206, -0.32978, -0.51524, 0.5026, 0.44518, -0.41282, 0.33215, -0.032643, 0.23382, 0.068028, -0.079137, 0.47821, -0.17514, 0.077763, 0.21428, -0.46747, 0.31344, -0.56925, 0.59784, 0.066899, 0.20827, 0.54411, -0.72478, -0.0035688, 0.22487, 0.35049, -0.040805, 0.11252, -0.16417, 0.28461, 0.43424, 0.34098, -0.27205, 0.64251, 0.77129, -0.24036, -0.12203, -0.18944, 0.12603, -0.85211, -0.22276, -0.43415, 0.2337, 0.41605, -0.66573, 1.1912, 0.2776, -0.80715, -0.23507, 0.74769, -0.0066615, 0.22775, -0.0070054, -0.39856, 0.22202, 0.43487, -0.55411, -0.6639, 0.13468, 0.20789, -0.17928, -0.20626, 0.73467, 0.54894, 0.40077, 0.063216, -0.026543, -0.72435, -0.61129, -0.079665, -0.63886, -0.27314, -0.2861, 0.26289, 0.48562, -0.13764, -0.078798, 0.36975, -0.055627, 1.1485, 0.039506, -0.89829, 0.23682, -0.36148, -0.11356, -0.072841, -0.79757, -0.49976, -0.21447, -0.049037, 0.39696, -0.17424, -0.41205, 1.1871, 0.5167, -0.059791, 0.71421, 0.1655, 0.33953, -0.10358, 0.29297, -0.26831, 0.1768, 0.3269, -0.42351, -0.11839, 0.16728, 0.06569, -0.43177, 0.28575, 0.39147, 0.49807, -0.13639, -0.6024, -0.50789, 0.052283, 0.3962, 0.86925, -0.096854, -1.1966, 0.042479, -1.2523, -0.12236, -0.12434, 0.31724, -0.28243, 0.18327, -0.080857, 0.14132, 0.55221, -0.27664, 0.31122, 0.075609, 0.22901, -0.0070232, -0.19509, 0.26924, -0.48834, -0.34159, 0.34529, 0.032231, -0.38957, 0.05093]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('Datasets/glove.6B/glove.6B.300d.txt', 'r') as f:\n",
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] == 'pizza':\n",
    "            print(sr[0])\n",
    "            print([float(i) for i in sr[1:]])\n",
    "            print(len([float(i) for i in sr[1:]]))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the vectors associated to pizza, food and sport in Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'food': [0.38544, 0.34247, 0.29599, -0.262, 0.037383, 0.45544, 0.49097, 0.11481, -0.11437, -1.9067, 0.035563, -1.1094, -0.26512, 0.64418, -0.031008, -0.3513, -0.0010547, 0.074658, -0.30369, -0.28188, -0.34342, 0.36205, 0.71009, 0.30243, 0.070325, 0.29492, -0.16233, 0.30998, 0.13705, 0.11847, -0.68642, 0.43305, -0.61518, 0.23643, -0.84174, 0.14667, -0.096616, -0.20908, -0.42296, -0.27254, -0.79343, -0.62781, 0.64804, 0.11541, -0.33486, -0.14101, 0.12864, -0.25123, -0.26515, 0.30876, -0.063111, 0.17893, 0.41197, 0.019621, -0.15406, 0.17542, 0.39268, 0.088817, 0.018012, -0.22508, -0.31832, 0.022296, 0.59453, 0.056538, -0.72464, -0.31751, -0.3865, 0.33806, -0.16237, -0.0076169, 0.52897, 0.14628, -0.22458, -0.66751, 0.23012, -0.068667, 0.4668, 0.2204, -0.38321, -0.18401, 0.36828, 0.085637, -0.28836, 0.43894, 0.1579, -1.1443, -0.17327, -0.0027353, -0.32621, -0.2411, -0.14597, 0.061719, -0.3021, -0.16319, 0.0025848, 0.26203, 0.045155, -0.019056, -0.48923, 0.062269, 0.1214, 0.054817, 0.01157, -0.16724, -0.30459, -0.53924, -0.21938, 0.049682, -0.19532, 0.024412, 0.18323, -0.22832, -0.375, -0.25533, 0.24311, 0.008097, 0.044543, 0.41836, 0.26278, 0.20927, -0.45486, 0.14258, 0.36823, 0.64177, 0.049307, -0.038022, 0.033907, -0.1173, 0.40365, 0.23042, 0.20191, -0.099931, 0.60634, -0.069024, -0.11417, -0.11435, 0.1171, 0.25884, -0.059129, 1.027, -0.065444, 0.33082, 0.41195, -0.51409, -0.46449, 0.49719, 0.18368, 0.11482, 0.20175, -0.4858, -0.11395, 0.24271, 0.53452, -0.17599, -0.18241, 0.085407, -0.27614, -0.33535, 0.13731, -0.38903, 0.47308, -0.28132, 0.29753, -0.16403, -0.51195, 0.25532, 0.26516, -0.6139, 0.013088, 0.35948, 0.16281, 0.31889, -0.57797, 0.25247, -0.55389, 0.56864, 0.089668, -0.20646, 0.10619, -0.12391, -0.40631, -0.29375, -0.6114, -0.21382, 0.077146, 0.22001, 0.33794, 0.11534, 0.22742, -0.25098, -0.15659, 0.7597, -1.1835, -0.37791, -0.34801, 0.29379, -0.48425, 0.175, 0.19507, 0.84789, -0.1802, -0.14255, 0.61267, 0.48842, -0.18246, 0.15696, 0.29159, -0.33145, 0.065447, -0.2671, -0.49741, -0.35313, -0.08501, 0.13289, -0.058364, 0.70297, 0.21803, -0.23166, 0.23356, 0.45469, 0.77361, -0.25131, -0.05397, -0.033968, -0.033857, -0.2106, 0.26651, 0.40503, 0.21139, 0.31596, 0.23324, 0.42179, -0.42393, 0.29181, 0.17072, 0.49736, 0.39993, 0.076354, -0.59329, -0.037345, -0.39826, -0.28424, -0.026921, -0.31003, -1.46, 0.012187, 0.19133, 0.08535, -0.016125, 0.26185, 0.52257, 0.11262, -0.1481, 0.15431, 0.48882, 0.416, -0.53778, -0.51524, -0.27682, 0.31711, -0.078578, -0.86162, -0.51523, -0.97632, 0.21927, -0.00083264, -0.0027921, 0.25754, 0.29383, -0.20229, -0.61117, 0.31172, -0.21503, 0.038843, 0.26046, -0.1239, -2.3409, 0.30863, -0.29139, -0.09166, -0.24405, 0.10426, 0.23199, 0.23967, -0.18697, 0.14248, 0.71032, -0.33381, 0.11111, -0.10267, 0.21123, -0.18594, -0.079114, -0.11809, -0.08642, 0.1409, -0.27209, -0.49944, -0.2751, -0.61361], 'sport': [0.34566, 0.15934, 0.48444, -0.13693, 0.18737, 0.2678, -0.39159, 0.4931, -0.76111, -1.4586, 0.41475, 0.55837, 0.021504, 0.28509, -0.30284, 0.021432, 0.071542, 0.53333, 0.18084, -0.40818, -0.37935, 0.86781, 0.4492, 0.67524, 0.052925, -0.42635, 0.46103, 0.031358, 0.5166, -0.081332, 0.35399, -0.53411, -0.22646, -0.091881, -0.5428, 0.61143, 0.67188, 0.079147, -0.21608, 0.2817, 0.22489, 0.0087532, 0.096962, -0.19739, 0.61631, 0.19901, 0.37232, 0.13627, 0.18799, 0.35549, -0.74315, -0.08624, 0.1883, -0.53688, 0.082768, 0.78362, -0.31835, -0.21211, -0.023984, 0.0095728, 0.28296, 0.30896, -0.38585, -0.55332, -0.66063, 0.30262, -0.65959, 0.25509, -0.55906, -0.3507, -0.11521, 0.32024, -0.25448, 0.12392, -0.22941, -0.30697, -0.073869, -0.021054, 0.26082, 0.45367, 0.32809, 0.56492, 0.067392, -0.54504, -0.45747, 0.29705, -0.007364, -0.15747, -0.19674, 0.44562, 0.10822, -0.010847, -0.020063, -0.54242, 0.85393, -0.098667, 0.22144, -0.1058, 0.08902, 0.059909, 0.17442, 0.34239, 0.071011, 0.32127, 0.099133, 0.60742, 0.52472, -0.13034, -0.10823, 0.16208, 0.30687, -0.079381, 0.046322, -0.96637, -0.034772, -0.032899, 0.44984, -0.0086, -0.24193, 0.067582, -0.13938, 0.19137, 0.46692, 0.58191, -0.20529, -0.29932, -0.19122, 0.47751, 0.011554, 0.016327, 0.14571, -0.29702, -0.22549, 0.078491, -0.2856, 0.027681, -0.050709, 0.08904, -0.10603, 0.5987, 0.17281, 0.0021526, 0.93064, -0.057695, 0.17412, -0.31447, 0.0025599, -0.079155, -0.08038, 0.62715, 0.62819, 0.25948, -0.25359, -0.38077, 0.30185, -0.93266, -0.02277, 0.40116, -0.0079393, -0.029146, 0.2834, -0.42381, -0.75231, -0.03341, 0.18793, -0.80745, -0.1471, 0.12451, 0.16207, -0.83302, -0.48239, 0.12213, -1.0567, 0.60332, 0.25437, -0.12537, 0.28882, -0.13624, 0.16769, 0.82878, 0.33491, 0.57352, 0.0038668, 0.052082, 0.87144, -0.40841, 0.0081564, 0.0021284, -0.33046, -0.16384, -0.31893, -0.16997, -0.24397, 0.24522, 0.19511, -0.17615, -0.12781, 0.61104, 0.62262, -0.28578, 1.032, -0.24093, -0.072303, 0.065576, -0.45258, -0.15914, 0.27673, 0.046784, -0.23509, 0.078567, 0.18001, 0.023338, -0.7807, 0.48395, -0.13503, 0.15531, 0.12585, 0.14729, -0.3931, -0.44495, -0.0121, -0.49026, 0.33196, -0.63298, 0.49953, -0.25245, -0.30707, 0.30539, -0.0075252, 0.1769, 0.20692, -0.59478, 0.3011, -0.38093, 0.36627, -0.05798, 0.35727, 0.65025, -0.23389, -0.056722, 0.35972, -0.15963, 0.15001, -0.056637, -0.63519, 0.13256, -0.4007, -0.19513, -0.27042, 0.33505, -0.15308, -0.058018, -0.025477, -0.4279, 0.013337, -0.26202, -0.012633, -0.34509, 0.14835, -0.63398, -0.15411, -0.82738, 0.37643, 0.11571, 0.39404, -0.36529, -0.3185, 0.35226, -0.20441, 0.10508, -0.022458, 0.32689, -0.22491, -0.14179, 0.79285, 0.3091, -1.7894, -0.24364, 0.33151, 0.60022, -0.088763, 0.11163, -0.1362, 0.32127, 0.017934, -0.6352, -0.61595, -0.24006, 0.13802, 0.36619, 0.19734, 0.35701, -0.42228, -0.25242, -0.050651, -0.041129, 0.15092, 0.22084, 0.52252, -0.27224], 'pizza': [0.25734, 0.4834, 0.39895, -0.021904, -0.23251, 0.1912, -0.060446, -0.25761, -0.45211, 0.041514, -0.2691, -0.70659, -0.19061, 0.61703, -0.31782, 0.027941, -0.16662, -0.10881, -0.34464, 0.42024, 0.36226, 0.72459, -0.037924, -0.13019, 0.41046, -0.053523, 0.24423, 0.018026, 0.43282, -1.2634, -0.54086, 0.47269, 0.35893, -0.26779, -0.57371, 0.35586, -0.3969, -0.35332, -0.48882, 0.24765, 0.15628, 0.03886, 0.0079223, 0.54105, -0.13862, 0.32459, 1.0425, 0.12856, 0.036834, -0.22976, -0.087973, -0.69039, 0.35075, 0.56834, -0.19602, -0.2434, -0.075702, 0.37302, 0.14015, -0.24343, 0.79112, -0.25912, -0.017421, -0.46356, -0.12607, -0.37098, -0.23651, 0.50475, -0.30574, 0.28055, 0.52918, 0.15871, -0.098648, -0.40663, 0.13522, -0.23016, -0.15465, -0.10037, -0.06647, -0.35895, -0.12413, 0.44327, 0.082424, -0.44134, -0.14447, -0.48395, 0.29215, 0.24427, -0.32845, 0.054433, 0.2512, 0.13315, -0.16265, -0.12271, -0.0041962, 0.048386, -0.28681, 0.20425, -0.40364, 0.097275, 0.33175, -0.087691, 0.010024, -0.51279, -0.083069, -0.39199, 0.15068, 0.75919, -0.2137, 0.15024, 0.36299, 0.031102, 0.28151, -0.5998, 0.44464, -0.63282, -0.61203, 0.24946, -0.3671, -0.056996, -0.17517, 0.16251, 0.80415, -0.10598, -0.30048, 0.18238, 0.048485, 0.13027, -0.33109, -0.13229, 0.047343, 0.43838, -0.18593, -0.018344, 0.19721, -0.23306, 0.030151, 0.19396, -0.145, 0.381, 0.15014, 0.052432, -0.27918, -0.39125, -0.29462, 0.15047, -0.081706, 0.4011, -0.0575, -0.50655, -0.47707, 1.0189, 0.31265, -0.041707, -0.47167, -0.29949, -0.11954, 0.27206, -0.32978, -0.51524, 0.5026, 0.44518, -0.41282, 0.33215, -0.032643, 0.23382, 0.068028, -0.079137, 0.47821, -0.17514, 0.077763, 0.21428, -0.46747, 0.31344, -0.56925, 0.59784, 0.066899, 0.20827, 0.54411, -0.72478, -0.0035688, 0.22487, 0.35049, -0.040805, 0.11252, -0.16417, 0.28461, 0.43424, 0.34098, -0.27205, 0.64251, 0.77129, -0.24036, -0.12203, -0.18944, 0.12603, -0.85211, -0.22276, -0.43415, 0.2337, 0.41605, -0.66573, 1.1912, 0.2776, -0.80715, -0.23507, 0.74769, -0.0066615, 0.22775, -0.0070054, -0.39856, 0.22202, 0.43487, -0.55411, -0.6639, 0.13468, 0.20789, -0.17928, -0.20626, 0.73467, 0.54894, 0.40077, 0.063216, -0.026543, -0.72435, -0.61129, -0.079665, -0.63886, -0.27314, -0.2861, 0.26289, 0.48562, -0.13764, -0.078798, 0.36975, -0.055627, 1.1485, 0.039506, -0.89829, 0.23682, -0.36148, -0.11356, -0.072841, -0.79757, -0.49976, -0.21447, -0.049037, 0.39696, -0.17424, -0.41205, 1.1871, 0.5167, -0.059791, 0.71421, 0.1655, 0.33953, -0.10358, 0.29297, -0.26831, 0.1768, 0.3269, -0.42351, -0.11839, 0.16728, 0.06569, -0.43177, 0.28575, 0.39147, 0.49807, -0.13639, -0.6024, -0.50789, 0.052283, 0.3962, 0.86925, -0.096854, -1.1966, 0.042479, -1.2523, -0.12236, -0.12434, 0.31724, -0.28243, 0.18327, -0.080857, 0.14132, 0.55221, -0.27664, 0.31122, 0.075609, 0.22901, -0.0070232, -0.19509, 0.26924, -0.48834, -0.34159, 0.34529, 0.032231, -0.38957, 0.05093]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" # words = ['pizza', 'food', 'sport']\\n    words_vecs = {}\\n    for c, r in enumerate(f):\\n        sr = r.split()\\n        if sr[0] == 'pizza':\\n           words_vecs['pizza'] = [float(i) for i in sr[1:]]\\n        elif sr[0] == 'food':\\n           words_vecs['food'] = [float(i) for i in sr[1:]]\\n        elif sr[0] == 'sport':\\n           words_vecs['sport'] = [float(i) for i in sr[1:]]\\n        \\n    print(words_vecs)\\n    # verify that the pizza and food are closer together than pizza and sport, using Euclidean distance\\n    distance_p_f = np.linalg.norm( words_vecs['pizza'], words_vecs['food'])\\n    print(distance_p_f)\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "with codecs.open('Datasets/glove.6B/glove.6B.300d.txt', 'r') as f:\n",
    "    ls = {}\n",
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] in ['pizza', 'food', 'sport']:\n",
    "            ls[sr[0]] =[float(i) for i in sr[1:]]\n",
    "        if len(ls) == 3:\n",
    "            break\n",
    "\n",
    "print(ls)\n",
    "''' # words = ['pizza', 'food', 'sport']\n",
    "    words_vecs = {}\n",
    "    for c, r in enumerate(f):\n",
    "        sr = r.split()\n",
    "        if sr[0] == 'pizza':\n",
    "           words_vecs['pizza'] = [float(i) for i in sr[1:]]\n",
    "        elif sr[0] == 'food':\n",
    "           words_vecs['food'] = [float(i) for i in sr[1:]]\n",
    "        elif sr[0] == 'sport':\n",
    "           words_vecs['sport'] = [float(i) for i in sr[1:]]\n",
    "        \n",
    "    print(words_vecs)\n",
    "    # verify that the pizza and food are closer together than pizza and sport, using Euclidean distance\n",
    "    distance_p_f = np.linalg.norm( words_vecs['pizza'], words_vecs['food'])\n",
    "    print(distance_p_f)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acitivty: Show that the vector of pizza is closer to vector of food than vector of sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.63426225303502"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.linalg.norm(np.array(ls['pizza']) - np.array(ls['food']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.341560240989656"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array(ls['pizza']) - np.array(ls['sport']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.896379012366626"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.array(ls['food']) - np.array(ls['sport']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [3, 4], [1, 2], [0, 0]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort a dictionary by its values\n",
    "x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}\n",
    "y = {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "#{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}\n",
    "z = [sorted([value, key]) for key, value in x.items()]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
